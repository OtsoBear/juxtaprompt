var e=Object.defineProperty,t=(t,s,o)=>(((t,s,o)=>{s in t?e(t,s,{enumerable:!0,configurable:!0,writable:!0,value:o}):t[s]=o})(t,"symbol"!=typeof s?s+"":s,o),o);import{o as s,s as o,l as r,n,a,e as i,b as c}from"./validation-a5e6ff80.js";const u=s({id:o(),object:r("chat.completion.chunk"),created:n(),model:o(),choices:a(s({index:n(),delta:s({content:o().optional(),role:o().optional()}),finish_reason:o().nullable()}))});s({error:s({message:o(),type:o(),param:o().nullable().optional(),code:o().nullable().optional()})});const l=s({type:i(["message_start","content_block_start","content_block_delta","content_block_stop","message_delta","message_stop"]),message:s({id:o(),type:r("message"),role:r("assistant"),content:a(s({type:r("text"),text:o()})),model:o(),stop_reason:o().nullable().optional(),stop_sequence:o().nullable().optional(),usage:s({input_tokens:n(),output_tokens:n()}).optional()}).optional(),delta:s({type:r("text_delta").optional(),text:o().optional(),stop_reason:o().nullable().optional(),stop_sequence:o().nullable().optional()}).optional(),content_block:s({type:r("text"),text:o()}).optional(),index:n().optional()});s({type:r("error"),error:s({type:o(),message:o()})});const d=s({candidates:a(s({content:s({parts:a(s({text:o()})),role:o()}),finishReason:o().optional(),index:n(),safetyRatings:a(s({category:o(),probability:o()})).optional()})),promptFeedback:s({safetyRatings:a(s({category:o(),probability:o()}))}).optional()});s({error:s({code:n(),message:o(),status:o()})});const p=s({provider:i(["openai","anthropic","gemini"]),apiKey:o().min(1,"API key is required"),baseUrl:o().url("Invalid base URL"),model:o().min(1,"Model is required"),temperature:n().min(0).max(2),maxTokens:n().min(1).max(32e3),topP:n().min(0).max(1),frequencyPenalty:n().min(-2).max(2),presencePenalty:n().min(-2).max(2),systemMessage:o()}),m=s({prompts:a(o()),config:s({provider:i(["openai","anthropic","gemini"]).optional(),model:o().optional(),temperature:n().min(0).max(2).optional(),maxTokens:n().min(1).max(32e3).optional(),topP:n().min(0).max(1).optional(),frequencyPenalty:n().min(-2).max(2).optional(),presencePenalty:n().min(-2).max(2).optional(),systemMessage:o().optional()}),ui:s({gridColumns:n().min(1).max(6).optional(),autoSend:c().optional(),debounceMs:n().min(0).max(5e3).optional(),showAdvancedSettings:c().optional(),theme:i(["light","dark","system"]).optional()})}),g=s({type:i(["none","session","local"]),acknowledgedRisks:c()});function h(e){const t=m.safeParse(e);return t.success?{success:!0,data:t.data}:{success:!1,error:{code:"VALIDATION_ERROR",message:"Invalid URL state format",details:t.error.issues}}}function f(e){const t=g.safeParse(e);return t.success?{success:!0,data:t.data}:{success:!1,error:{code:"VALIDATION_ERROR",message:"Invalid storage preference",details:t.error.issues}}}class y extends Error{constructor(e){super(e.message),t(this,"code"),t(this,"retryable"),t(this,"statusCode"),t(this,"details"),this.name="LLMProviderError",this.code=e.code,this.retryable=e.retryable,void 0!==e.statusCode&&(this.statusCode=e.statusCode),void 0!==e.details&&(this.details=e.details)}}const v=class e{constructor(){t(this,"defaultTimeout",3e4),t(this,"maxRetries",3),t(this,"cacheTimeout",6e5)}async getAvailableModels(t,s){const o=`${this.name}_${t.slice(-8)}_${s||"default"}`,r=e.modelCache.get(o);if(r&&Date.now()-r.timestamp<this.cacheTimeout)return{models:r.models,cached:!0,timestamp:r.timestamp};try{const r=await this.fetchAvailableModels(t,s);return e.modelCache.set(o,{models:r,timestamp:Date.now()}),{models:r,cached:!1,timestamp:Date.now()}}catch(n){return r?{models:r.models,cached:!0,timestamp:r.timestamp}:{models:this.getFallbackModels(),cached:!1,timestamp:Date.now()}}}clearModelCache(){e.modelCache.clear()}validateConfig(e){return function(e){const t=p.safeParse(e);return t.success?{success:!0,data:t.data}:{success:!1,error:{code:"VALIDATION_ERROR",message:"Invalid LLM configuration",details:t.error.issues}}}(e)}createError(e,t,s=!1,o,r){return{code:e,message:t,retryable:s,...void 0!==o&&{statusCode:o},...void 0!==r&&{details:r}}}async handleHTTPError(e){let t,s=`HTTP ${e.status}: ${e.statusText}`;try{const o=await e.text();if(o)try{if(t=JSON.parse(o),"object"==typeof t&&null!==t){const e=t;if(e.error&&"object"==typeof e.error){const t=e.error;"string"==typeof t.message&&(s=t.message)}else"string"==typeof e.message&&(s=e.message)}}catch{t=o}}catch{}const o=e.status>=500||429===e.status;return this.createError(`HTTP_${e.status}`,s,o,e.status,t)}handleNetworkError(e){const t=e instanceof Error?e.message:"Unknown network error";return this.createError("NETWORK_ERROR",t,!0,void 0,e)}handleParsingError(e,t){const s=e instanceof Error?e.message:"Failed to parse response";return this.createError("PARSING_ERROR",s,!1,void 0,{error:e,data:t})}createHeaders(e,t={}){return{"Content-Type":"application/json","User-Agent":"Juxtaprompt/1.0.0",...t,...this.getAuthHeaders(e)}}async*processSSEStream(e,t){var s;const o=null==(s=e.body)?void 0:s.getReader();if(!o)throw new y(this.createError("NO_RESPONSE_BODY","No response body received",!1));const r=new TextDecoder;let n="";try{for(;;){const{done:e,value:s}=await o.read();if(e)break;n+=r.decode(s,{stream:!0});const i=n.split("\n");n=i.pop()||"";for(const o of i)if(o.startsWith("data: ")){const e=o.slice(6);if("[DONE]"===e)return void(yield{requestId:t,content:"",isComplete:!0});try{const s=this.parseStreamChunk(e,t);s&&(yield s)}catch(a){continue}}}}finally{o.releaseLock()}}async makeRequest(e,t,s=this.defaultTimeout){const o=new AbortController,r=setTimeout(()=>o.abort(),s);try{const s=await fetch(e,{...t,signal:o.signal});if(clearTimeout(r),!s.ok){const e=await this.handleHTTPError(s);throw new y(e)}return s}catch(n){if(clearTimeout(r),n instanceof y)throw n;if(n instanceof Error&&"AbortError"===n.name)throw new y(this.createError("TIMEOUT_ERROR",`Request timed out after ${s}ms`,!0));const e=this.handleNetworkError(n);throw new y(e)}}generateRequestId(){return`${this.name}_${Date.now()}_${Math.random().toString(36).substr(2,9)}`}logRequest(e){"undefined"!=typeof window&&window.location.hostname}logResponse(e){"undefined"!=typeof window&&"localhost"===window.location.hostname&&e.isComplete}};t(v,"modelCache",new Map);let k=v;const R=new class{constructor(){t(this,"providers",new Map),t(this,"activeRequests",new Map)}registerProvider(e){this.providers.set(e.name,e)}getProvider(e){return this.providers.get(e)??null}getRegisteredProviders(){return Array.from(this.providers.keys())}hasProvider(e){return this.providers.has(e)}async*sendStreamingRequest(e){const t=this.getProvider(e.config.provider);if(!t)throw new y({code:"PROVIDER_NOT_FOUND",message:`Provider '${e.config.provider}' is not registered`,retryable:!1});const s=t.validateConfig(e.config);if(!s.success)throw new y({code:"INVALID_CONFIG",message:`Invalid configuration: ${s.error.message}`,retryable:!1,details:s.error.details});const o=new AbortController;this.activeRequests.set(e.id,o);try{for await(const s of t.sendStreamingRequest(e)){if(o.signal.aborted)return void(yield{requestId:e.id,content:"",isComplete:!0});yield s}}finally{this.activeRequests.delete(e.id)}}cancelRequest(e){const t=this.activeRequests.get(e);return!!t&&(t.abort(),this.activeRequests.delete(e),!0)}cancelAllRequests(){for(const e of this.activeRequests.values())e.abort();this.activeRequests.clear()}getActiveRequestCount(){return this.activeRequests.size}getActiveRequestIds(){return Array.from(this.activeRequests.keys())}async getAvailableModels(e,t,s){const o=this.getProvider(e);if(!o)throw new y({code:"PROVIDER_NOT_FOUND",message:`Provider '${e}' is not registered`,retryable:!1});return o.getAvailableModels(t,s)}clearModelCache(e){const t=this.getProvider(e);t&&"clearModelCache"in t&&t.clearModelCache()}clearAllModelCaches(){for(const e of this.providers.values())"clearModelCache"in e&&e.clearModelCache()}validateConfig(e,t){const s=this.getProvider(e);return s?s.validateConfig(t):{success:!1,error:{code:"PROVIDER_NOT_FOUND",message:`Provider '${e}' is not registered`}}}createRequest(e,t,s){const o=this.validateConfig(t.provider,t);if(!o.success)return o;return{success:!0,data:{id:s??this.generateRequestId(t.provider),prompt:e,config:o.data,timestamp:Date.now()}}}generateRequestId(e){return`${e}_${Date.now()}_${Math.random().toString(36).substr(2,9)}`}getProviderStats(){const e={},t=["openai","anthropic","gemini"];for(const s of t)e[s]={registered:this.hasProvider(s),activeRequests:0};for(const s of this.activeRequests.keys()){const t=s.split("_")[0];e[t]&&e[t].activeRequests++}return e}dispose(){this.cancelAllRequests(),this.providers.clear()}};const b=new class extends k{constructor(){super(...arguments),t(this,"name","openai")}async*sendStreamingRequest(e){this.logRequest(e);const t=`${e.config.baseUrl}/chat/completions`,s=this.createHeaders(e.config.apiKey),o=this.createRequestBody(e);try{const r=await this.makeRequest(t,{method:"POST",headers:s,body:JSON.stringify(o)});yield*this.processSSEStream(r,e.id)}catch(r){if(r instanceof y)throw r;const e=this.handleNetworkError(r);throw new y(e)}}getAuthHeaders(e){return{Authorization:`Bearer ${e}`}}createRequestBody(e){const t=[];return e.config.systemMessage.trim()&&t.push({role:"system",content:e.config.systemMessage}),t.push({role:"user",content:e.prompt}),{model:e.config.model,messages:t,temperature:e.config.temperature,max_tokens:e.config.maxTokens,top_p:e.config.topP,frequency_penalty:e.config.frequencyPenalty,presence_penalty:e.config.presencePenalty,stream:!0}}parseStreamChunk(e,t){var s;try{const o=JSON.parse(e),r=this.validateStreamChunk(o);if(!r.success)return null;const n=r.data.choices[0];if(!n)return null;const a=n.delta.content||"",i=null!==n.finish_reason,c={requestId:t,content:a,isComplete:i,...i&&(null==(s=o.usage)?void 0:s.total_tokens)&&{tokenCount:o.usage.total_tokens}};return this.logResponse(c),c}catch(o){return null}}validateStreamChunk(e){return function(e){const t=u.safeParse(e);return t.success?{success:!0,data:t.data}:{success:!1,error:{code:"VALIDATION_ERROR",message:"Invalid OpenAI response format",details:t.error.issues}}}(e)}async*processSSEStream(e,t){var s;const o=null==(s=e.body)?void 0:s.getReader();if(!o)throw new y(this.createError("NO_RESPONSE_BODY","No response body received from OpenAI",!1));const r=new TextDecoder;let n="";try{for(;;){const{done:e,value:s}=await o.read();if(e)break;n+=r.decode(s,{stream:!0});const a=n.split("\n");n=a.pop()||"";for(const o of a){const e=o.trim();if(e.startsWith("data: ")){const s=e.slice(6);if("[DONE]"===s)return void(yield{requestId:t,content:"",isComplete:!0});const o=this.parseStreamChunk(s,t);if(o&&(yield o,o.isComplete))return}}}}catch(a){const e=this.handleParsingError(a);throw new y(e)}finally{o.releaseLock()}}async handleHTTPError(e){var t;let s,o=`OpenAI API error: ${e.status} ${e.statusText}`;try{const r=await e.text();if(r)try{const e=JSON.parse(r);s=e,(null==(t=e.error)?void 0:t.message)&&(o=e.error.message)}catch{s=r}}catch{}const r=e.status>=500||429===e.status||408===e.status;return this.createError(`OPENAI_HTTP_${e.status}`,o,r,e.status,s)}async fetchAvailableModels(e,t){const s=`${t||"https://api.openai.com/v1"}/models`,o=this.createHeaders(e);try{const e=await this.makeRequest(s,{method:"GET",headers:o}),t=await e.json();if(!t.data||!Array.isArray(t.data))throw new Error("Invalid response format from OpenAI models API");return t.data.filter(e=>e.id&&(e.id.startsWith("gpt-")||e.id.includes("chat")||e.id.includes("turbo"))).map(e=>({id:e.id,name:e.id,description:this.getModelDescription(e.id),contextLength:this.getModelContextLength(e.id),maxOutputTokens:this.getModelMaxOutputTokens(e.id),pricing:this.getModelPricing(e.id)})).sort((e,t)=>{const s=e=>e.includes("gpt-4o")?1:e.includes("gpt-4")?2:e.includes("gpt-3.5")?3:4;return s(e.id)-s(t.id)})}catch(r){throw r}}getFallbackModels(){return[{id:"gpt-4o",name:"GPT-4o",description:"Most advanced multimodal model",contextLength:128e3,maxOutputTokens:4096,pricing:{input:5,output:15}},{id:"gpt-4o-mini",name:"GPT-4o Mini",description:"Affordable and intelligent small model",contextLength:128e3,maxOutputTokens:16384,pricing:{input:.15,output:.6}},{id:"gpt-4-turbo",name:"GPT-4 Turbo",description:"Previous generation flagship model",contextLength:128e3,maxOutputTokens:4096,pricing:{input:10,output:30}},{id:"gpt-4",name:"GPT-4",description:"Original GPT-4 model",contextLength:8192,maxOutputTokens:4096,pricing:{input:30,output:60}},{id:"gpt-3.5-turbo",name:"GPT-3.5 Turbo",description:"Fast and affordable model",contextLength:16385,maxOutputTokens:4096,pricing:{input:.5,output:1.5}}]}getModelDescription(e){return{"gpt-4o":"Most advanced multimodal model","gpt-4o-mini":"Affordable and intelligent small model","gpt-4-turbo":"Previous generation flagship model","gpt-4":"Original GPT-4 model","gpt-3.5-turbo":"Fast and affordable model"}[e]||"OpenAI language model"}getModelContextLength(e){return{"gpt-4o":128e3,"gpt-4o-mini":128e3,"gpt-4-turbo":128e3,"gpt-4":8192,"gpt-3.5-turbo":16385}[e]||4096}getModelMaxOutputTokens(e){return{"gpt-4o":4096,"gpt-4o-mini":16384,"gpt-4-turbo":4096,"gpt-4":4096,"gpt-3.5-turbo":4096}[e]||4096}getModelPricing(e){return{"gpt-4o":{input:5,output:15},"gpt-4o-mini":{input:.15,output:.6},"gpt-4-turbo":{input:10,output:30},"gpt-4":{input:30,output:60},"gpt-3.5-turbo":{input:.5,output:1.5}}[e]||{input:1,output:2}}validateConfig(e){const t=super.validateConfig(e);if(!t.success)return t;const s=t.data;if("openai"!==s.provider)return{success:!1,error:{code:"INVALID_PROVIDER",message:'Provider must be "openai" for OpenAI provider'}};if(!s.apiKey.startsWith("sk-"))return{success:!1,error:{code:"INVALID_API_KEY",message:'OpenAI API key must start with "sk-"'}};const o=["gpt-4o","gpt-4o-mini","gpt-4-turbo","gpt-4","gpt-3.5-turbo"];if(!o.includes(s.model))return{success:!1,error:{code:"UNSUPPORTED_MODEL",message:`Model "${s.model}" is not supported. Supported models: ${o.join(", ")}`}};const r=s.baseUrl.replace(/\/$/,"");return["https://api.openai.com/v1","https://api.openai.com/v1/"].some(e=>e.replace(/\/$/,"")===r),{success:!0,data:s}}};const P=new class extends k{constructor(){super(...arguments),t(this,"name","anthropic")}async*sendStreamingRequest(e){this.logRequest(e);const t=`${e.config.baseUrl}/v1/messages`,s=this.createHeaders(e.config.apiKey,{"anthropic-version":"2023-06-01"}),o=this.createRequestBody(e);try{const r=await this.makeRequest(t,{method:"POST",headers:s,body:JSON.stringify(o)});yield*this.processSSEStream(r,e.id)}catch(r){if(r instanceof y)throw r;const e=this.handleNetworkError(r);throw new y(e)}}getAuthHeaders(e){return{"x-api-key":e}}createRequestBody(e){const t=[];t.push({role:"user",content:e.prompt});const s={model:e.config.model,messages:t,max_tokens:e.config.maxTokens,temperature:e.config.temperature,top_p:e.config.topP,stream:!0};return e.config.systemMessage.trim()&&(s.system=e.config.systemMessage),s}parseStreamChunk(e,t){var s,o,r,n;try{const a=JSON.parse(e),i=this.validateStreamChunk(a);if(!i.success)return null;const c=i.data;switch(c.type){case"message_start":return{requestId:t,content:"",isComplete:!1};case"content_block_delta":return(null==(s=c.delta)?void 0:s.text)?{requestId:t,content:c.delta.text,isComplete:!1}:null;case"message_delta":if(null==(o=c.delta)?void 0:o.stop_reason){const e={requestId:t,content:"",isComplete:!0};return(null==(n=null==(r=c.message)?void 0:r.usage)?void 0:n.output_tokens)?{...e,tokenCount:c.message.usage.input_tokens+c.message.usage.output_tokens}:(this.logResponse(e),e)}return null;case"message_stop":{const e={requestId:t,content:"",isComplete:!0};return this.logResponse(e),e}default:return null}}catch(a){return null}}validateStreamChunk(e){return function(e){const t=l.safeParse(e);return t.success?{success:!0,data:t.data}:{success:!1,error:{code:"VALIDATION_ERROR",message:"Invalid Anthropic response format",details:t.error.issues}}}(e)}async*processSSEStream(e,t){var s;const o=null==(s=e.body)?void 0:s.getReader();if(!o)throw new y(this.createError("NO_RESPONSE_BODY","No response body received from Anthropic",!1));const r=new TextDecoder;let n="";try{for(;;){const{done:e,value:s}=await o.read();if(e)break;n+=r.decode(s,{stream:!0});const a=n.split("\n");n=a.pop()||"";for(const o of a){const e=o.trim();if(e.startsWith("data: ")){const s=e.slice(6);if(!s||"{}"===s)continue;const o=this.parseStreamChunk(s,t);if(o&&(yield o,o.isComplete))return}else if(e.startsWith("event: ")){if("message_stop"===e.slice(7))return void(yield{requestId:t,content:"",isComplete:!0})}}}}catch(a){const e=this.handleParsingError(a);throw new y(e)}finally{o.releaseLock()}}async handleHTTPError(e){var t;let s,o=`Anthropic API error: ${e.status} ${e.statusText}`;try{const r=await e.text();if(r)try{const e=JSON.parse(r);s=e,(null==(t=e.error)?void 0:t.message)?o=e.error.message:e.message&&(o=e.message)}catch{s=r}}catch{}const r=e.status>=500||429===e.status||408===e.status;return this.createError(`ANTHROPIC_HTTP_${e.status}`,o,r,e.status,s)}async fetchAvailableModels(){return this.getFallbackModels()}getFallbackModels(){return[{id:"claude-3-5-sonnet-20241022",name:"Claude 3.5 Sonnet",description:"Most intelligent model, ideal for complex tasks",contextLength:2e5,maxOutputTokens:8192,pricing:{input:3,output:15}},{id:"claude-3-5-haiku-20241022",name:"Claude 3.5 Haiku",description:"Fastest model for everyday tasks",contextLength:2e5,maxOutputTokens:8192,pricing:{input:.8,output:4}},{id:"claude-3-opus-20240229",name:"Claude 3 Opus",description:"Powerful model for highly complex tasks",contextLength:2e5,maxOutputTokens:4096,pricing:{input:15,output:75}},{id:"claude-3-sonnet-20240229",name:"Claude 3 Sonnet",description:"Balance of intelligence and speed",contextLength:2e5,maxOutputTokens:4096,pricing:{input:3,output:15}},{id:"claude-3-haiku-20240307",name:"Claude 3 Haiku",description:"Fast and cost-effective model",contextLength:2e5,maxOutputTokens:4096,pricing:{input:.25,output:1.25}}]}validateConfig(e){const t=super.validateConfig(e);if(!t.success)return t;const s=t.data;if("anthropic"!==s.provider)return{success:!1,error:{code:"INVALID_PROVIDER",message:'Provider must be "anthropic" for Anthropic provider'}};if(!s.apiKey.startsWith("sk-ant-"))return{success:!1,error:{code:"INVALID_API_KEY",message:'Anthropic API key must start with "sk-ant-"'}};const o=["claude-3-5-sonnet-20241022","claude-3-5-haiku-20241022","claude-3-opus-20240229","claude-3-sonnet-20240229","claude-3-haiku-20240307"];if(!o.includes(s.model))return{success:!1,error:{code:"UNSUPPORTED_MODEL",message:`Model "${s.model}" is not supported. Supported models: ${o.join(", ")}`}};const r=s.baseUrl.replace(/\/$/,"");return["https://api.anthropic.com","https://api.anthropic.com/"].some(e=>e.replace(/\/$/,"")===r),s.maxTokens>8192?{success:!1,error:{code:"INVALID_MAX_TOKENS",message:"Anthropic models support a maximum of 8192 tokens"}}:{success:!0,data:s}}};const w=new class extends k{constructor(){super(...arguments),t(this,"name","gemini")}async*sendStreamingRequest(e){this.logRequest(e);const t=`${e.config.baseUrl}/models/${e.config.model}:streamGenerateContent`,s=this.createHeaders(e.config.apiKey),o=this.createRequestBody(e);try{const r=await this.makeRequest(t,{method:"POST",headers:s,body:JSON.stringify(o)});yield*this.processSSEStream(r,e.id)}catch(r){if(r instanceof y)throw r;const e=this.handleNetworkError(r);throw new y(e)}}getAuthHeaders(){return{}}createRequestBody(e){const t=[],s=e.config.systemMessage.trim()?{parts:[{text:e.config.systemMessage}]}:void 0;t.push({role:"user",parts:[{text:e.prompt}]});const o={contents:t,generationConfig:{temperature:e.config.temperature,maxOutputTokens:e.config.maxTokens,topP:e.config.topP}};return s&&(o.systemInstruction=s),o}parseStreamChunk(e,t){var s,o,r,n;try{const a=JSON.parse(e),i=this.validateStreamChunk(a);if(!i.success)return null;const c=null==(s=i.data.candidates)?void 0:s[0];if(!c)return null;const u=(null==(n=null==(r=null==(o=c.content)?void 0:o.parts)?void 0:r[0])?void 0:n.text)||"",l=void 0!==c.finishReason,d={requestId:t,content:u,isComplete:l};return l&&this.logResponse(d),d}catch(a){return null}}validateStreamChunk(e){return function(e){const t=d.safeParse(e);return t.success?{success:!0,data:t.data}:{success:!1,error:{code:"VALIDATION_ERROR",message:"Invalid Gemini response format",details:t.error.issues}}}(e)}async*processSSEStream(e,t){var s;const o=null==(s=e.body)?void 0:s.getReader();if(!o)throw new y(this.createError("NO_RESPONSE_BODY","No response body received from Gemini",!1));const r=new TextDecoder;let n="";try{for(;;){const{done:e,value:s}=await o.read();if(e)break;n+=r.decode(s,{stream:!0});const a=n.split("\n");n=a.pop()||"";for(const o of a){const e=o.trim();if(e.startsWith("data: ")){const s=e.slice(6);if(!s||"{}"===s)continue;const o=this.parseStreamChunk(s,t);if(o&&(yield o,o.isComplete))return}}}}catch(a){const e=this.handleParsingError(a);throw new y(e)}finally{o.releaseLock()}}async makeRequest(e,t,s=this.defaultTimeout){const o=new URL(e),r=t.headers||{};let n="";if(t.body&&"string"==typeof t.body)try{const e=r.Authorization;(null==e?void 0:e.startsWith("Bearer "))&&(n=e.slice(7))}catch{}return n&&(o.searchParams.set("key",n),delete r.Authorization),super.makeRequest(o.toString(),{...t,headers:r},s)}createHeaders(e,t={}){return{"Content-Type":"application/json","User-Agent":"Juxtaprompt/1.0.0",Authorization:`Bearer ${e}`,...t}}async handleHTTPError(e){var t;let s,o=`Gemini API error: ${e.status} ${e.statusText}`;try{const r=await e.text();if(r)try{const e=JSON.parse(r);s=e,(null==(t=e.error)?void 0:t.message)?o=e.error.message:e.message&&(o=e.message)}catch{s=r}}catch{}const r=e.status>=500||429===e.status||408===e.status;return this.createError(`GEMINI_HTTP_${e.status}`,o,r,e.status,s)}async fetchAvailableModels(e,t){const s=`${t||"https://generativelanguage.googleapis.com/v1beta"}/models`;try{const t=await fetch(`${s}?key=${e}`,{method:"GET",headers:{"Content-Type":"application/json","User-Agent":"Juxtaprompt/1.0.0"}});if(!t.ok)throw new Error(`HTTP ${t.status}: ${t.statusText}`);const o=await t.json();if(!o.models||!Array.isArray(o.models))throw new Error("Invalid response format from Gemini models API");return o.models.filter(e=>{var t;return e.name&&(null==(t=e.supportedGenerationMethods)?void 0:t.includes("generateContent"))&&!e.name.includes("embedding")}).map(e=>{const t=e.name.replace("models/","");return{id:t,name:this.getModelDisplayName(t),description:e.description||this.getModelDescription(t),contextLength:this.getModelContextLength(t),maxOutputTokens:this.getModelMaxOutputTokens(t),pricing:this.getModelPricing(t)}}).sort((e,t)=>{const s=e=>e.includes("gemini-1.5-pro")?1:e.includes("gemini-1.5-flash")?2:e.includes("gemini-1.0-pro")?3:4;return s(e.id)-s(t.id)})}catch(o){throw o}}getFallbackModels(){return[{id:"gemini-1.5-pro",name:"Gemini 1.5 Pro",description:"Most capable model for complex reasoning tasks",contextLength:2e6,maxOutputTokens:8192,pricing:{input:1.25,output:5}},{id:"gemini-1.5-flash",name:"Gemini 1.5 Flash",description:"Fast and efficient model for everyday tasks",contextLength:1e6,maxOutputTokens:8192,pricing:{input:.075,output:.3}},{id:"gemini-1.0-pro",name:"Gemini 1.0 Pro",description:"Previous generation model",contextLength:32768,maxOutputTokens:2048,pricing:{input:.5,output:1.5}}]}getModelDisplayName(e){return{"gemini-1.5-pro":"Gemini 1.5 Pro","gemini-1.5-flash":"Gemini 1.5 Flash","gemini-1.0-pro":"Gemini 1.0 Pro"}[e]||e}getModelDescription(e){return{"gemini-1.5-pro":"Most capable model for complex reasoning tasks","gemini-1.5-flash":"Fast and efficient model for everyday tasks","gemini-1.0-pro":"Previous generation model"}[e]||"Google Gemini language model"}getModelContextLength(e){return{"gemini-1.5-pro":2e6,"gemini-1.5-flash":1e6,"gemini-1.0-pro":32768}[e]||32768}getModelMaxOutputTokens(e){return{"gemini-1.5-pro":8192,"gemini-1.5-flash":8192,"gemini-1.0-pro":2048}[e]||2048}getModelPricing(e){return{"gemini-1.5-pro":{input:1.25,output:5},"gemini-1.5-flash":{input:.075,output:.3},"gemini-1.0-pro":{input:.5,output:1.5}}[e]||{input:.5,output:1.5}}validateConfig(e){const t=super.validateConfig(e);if(!t.success)return t;const s=t.data;if("gemini"!==s.provider)return{success:!1,error:{code:"INVALID_PROVIDER",message:'Provider must be "gemini" for Gemini provider'}};if(s.apiKey.length<20)return{success:!1,error:{code:"INVALID_API_KEY",message:"Gemini API key appears to be too short"}};const o=["gemini-1.5-pro","gemini-1.5-flash","gemini-1.0-pro"];if(!o.includes(s.model))return{success:!1,error:{code:"UNSUPPORTED_MODEL",message:`Model "${s.model}" is not supported. Supported models: ${o.join(", ")}`}};const r=s.baseUrl.replace(/\/$/,"");return["https://generativelanguage.googleapis.com/v1beta","https://generativelanguage.googleapis.com/v1beta/"].some(e=>e.replace(/\/$/,"")===r),s.maxTokens>8192?{success:!1,error:{code:"INVALID_MAX_TOKENS",message:"Gemini models support a maximum of 8192 output tokens"}}:{success:!0,data:s}}};R.registerProvider(b),R.registerProvider(P),R.registerProvider(w);export{h as a,P as b,w as g,R as l,b as o,f as v};
//# sourceMappingURL=llm-services-bfcb06ee.js.map
